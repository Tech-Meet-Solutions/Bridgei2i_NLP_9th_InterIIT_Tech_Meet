{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "iiit-bart-xsum-finetune.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHloXPYyGndY",
        "outputId": "2608f463-df4e-42be-e91c-29e35a56260b"
      },
      "source": [
        "# !pip install -q transformers\n",
        "# bart-large-xsum, VictorSanh/bart-base-finetuned-xsum\n",
        "# !git clone https://github.com/huggingface/transformers\n",
        "%cd transformers\n",
        "# !pip install ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtL-3EtHJJwD",
        "outputId": "69000617-b3b0-41fe-a593-b8703012921a"
      },
      "source": [
        "%cd examples/legacy/seq2seq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers/examples/legacy/seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylAGiBGtcZrv"
      },
      "source": [
        "# !ls"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmVREMmBcjnC"
      },
      "source": [
        "#  !pip install -r requirements.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRwFqFGjcnPN",
        "outputId": "8b4d2107-8c34-4c7e-e431-1980b791f132"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx3tsKzvdBJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55da6774-3360-4117-e5d3-65942ad94992"
      },
      "source": [
        "!python finetune_trainer.py --help"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 13:55:17.092706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "usage: finetune_trainer.py [-h] --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                           [--config_name CONFIG_NAME]\n",
            "                           [--tokenizer_name TOKENIZER_NAME]\n",
            "                           [--cache_dir CACHE_DIR]\n",
            "                           [--freeze_encoder [FREEZE_ENCODER]]\n",
            "                           [--freeze_embeds [FREEZE_EMBEDS]] --data_dir\n",
            "                           DATA_DIR [--task TASK]\n",
            "                           [--max_source_length MAX_SOURCE_LENGTH]\n",
            "                           [--max_target_length MAX_TARGET_LENGTH]\n",
            "                           [--val_max_target_length VAL_MAX_TARGET_LENGTH]\n",
            "                           [--test_max_target_length TEST_MAX_TARGET_LENGTH]\n",
            "                           [--n_train N_TRAIN] [--n_val N_VAL]\n",
            "                           [--n_test N_TEST] [--src_lang SRC_LANG]\n",
            "                           [--tgt_lang TGT_LANG] [--eval_beams EVAL_BEAMS]\n",
            "                           [--no_ignore_pad_token_for_loss]\n",
            "                           [--ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]]\n",
            "                           --output_dir OUTPUT_DIR\n",
            "                           [--overwrite_output_dir [OVERWRITE_OUTPUT_DIR]]\n",
            "                           [--do_train [DO_TRAIN]] [--do_eval [DO_EVAL]]\n",
            "                           [--do_predict [DO_PREDICT]]\n",
            "                           [--evaluation_strategy {no,steps,epoch}]\n",
            "                           [--prediction_loss_only [PREDICTION_LOSS_ONLY]]\n",
            "                           [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                           [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                           [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\n",
            "                           [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\n",
            "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                           [--eval_accumulation_steps EVAL_ACCUMULATION_STEPS]\n",
            "                           [--learning_rate LEARNING_RATE]\n",
            "                           [--weight_decay WEIGHT_DECAY]\n",
            "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
            "                           [--adam_epsilon ADAM_EPSILON]\n",
            "                           [--max_grad_norm MAX_GRAD_NORM]\n",
            "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                           [--max_steps MAX_STEPS]\n",
            "                           [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]\n",
            "                           [--warmup_ratio WARMUP_RATIO]\n",
            "                           [--warmup_steps WARMUP_STEPS]\n",
            "                           [--logging_dir LOGGING_DIR]\n",
            "                           [--logging_strategy {no,steps,epoch}]\n",
            "                           [--logging_first_step [LOGGING_FIRST_STEP]]\n",
            "                           [--logging_steps LOGGING_STEPS]\n",
            "                           [--save_strategy {no,steps,epoch}]\n",
            "                           [--save_steps SAVE_STEPS]\n",
            "                           [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                           [--no_cuda [NO_CUDA]] [--seed SEED] [--fp16 [FP16]]\n",
            "                           [--fp16_opt_level FP16_OPT_LEVEL]\n",
            "                           [--fp16_backend {auto,amp,apex}]\n",
            "                           [--fp16_full_eval [FP16_FULL_EVAL]]\n",
            "                           [--local_rank LOCAL_RANK]\n",
            "                           [--tpu_num_cores TPU_NUM_CORES]\n",
            "                           [--tpu_metrics_debug [TPU_METRICS_DEBUG]]\n",
            "                           [--debug [DEBUG]]\n",
            "                           [--dataloader_drop_last [DATALOADER_DROP_LAST]]\n",
            "                           [--eval_steps EVAL_STEPS]\n",
            "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
            "                           [--past_index PAST_INDEX] [--run_name RUN_NAME]\n",
            "                           [--disable_tqdm DISABLE_TQDM]\n",
            "                           [--no_remove_unused_columns]\n",
            "                           [--remove_unused_columns [REMOVE_UNUSED_COLUMNS]]\n",
            "                           [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
            "                           [--load_best_model_at_end [LOAD_BEST_MODEL_AT_END]]\n",
            "                           [--metric_for_best_model METRIC_FOR_BEST_MODEL]\n",
            "                           [--greater_is_better GREATER_IS_BETTER]\n",
            "                           [--ignore_data_skip [IGNORE_DATA_SKIP]]\n",
            "                           [--sharded_ddp SHARDED_DDP] [--deepspeed DEEPSPEED]\n",
            "                           [--label_smoothing_factor LABEL_SMOOTHING_FACTOR]\n",
            "                           [--adafactor [ADAFACTOR]]\n",
            "                           [--group_by_length [GROUP_BY_LENGTH]]\n",
            "                           [--report_to REPORT_TO [REPORT_TO ...]]\n",
            "                           [--ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS]\n",
            "                           [--no_dataloader_pin_memory]\n",
            "                           [--dataloader_pin_memory [DATALOADER_PIN_MEMORY]]\n",
            "                           [--skip_memory_metrics [SKIP_MEMORY_METRICS]]\n",
            "                           [--label_smoothing LABEL_SMOOTHING]\n",
            "                           [--sortish_sampler [SORTISH_SAMPLER]]\n",
            "                           [--predict_with_generate [PREDICT_WITH_GENERATE]]\n",
            "                           [--encoder_layerdrop ENCODER_LAYERDROP]\n",
            "                           [--decoder_layerdrop DECODER_LAYERDROP]\n",
            "                           [--dropout DROPOUT]\n",
            "                           [--attention_dropout ATTENTION_DROPOUT]\n",
            "                           [--lr_scheduler LR_SCHEDULER]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                        Path to pretrained model or model identifier from\n",
            "                        huggingface.co/models\n",
            "  --config_name CONFIG_NAME\n",
            "                        Pretrained config name or path if not the same as\n",
            "                        model_name\n",
            "  --tokenizer_name TOKENIZER_NAME\n",
            "                        Pretrained tokenizer name or path if not the same as\n",
            "                        model_name\n",
            "  --cache_dir CACHE_DIR\n",
            "                        Where do you want to store the pretrained models\n",
            "                        downloaded from huggingface.co\n",
            "  --freeze_encoder [FREEZE_ENCODER]\n",
            "                        Whether tp freeze the encoder.\n",
            "  --freeze_embeds [FREEZE_EMBEDS]\n",
            "                        Whether to freeze the embeddings.\n",
            "  --data_dir DATA_DIR   The input data dir. Should contain the .tsv files (or\n",
            "                        other data files) for the task.\n",
            "  --task TASK           Task name, summarization (or summarization_{dataset}\n",
            "                        for pegasus) or translation\n",
            "  --max_source_length MAX_SOURCE_LENGTH\n",
            "                        The maximum total input sequence length after\n",
            "                        tokenization. Sequences longer than this will be\n",
            "                        truncated, sequences shorter will be padded.\n",
            "  --max_target_length MAX_TARGET_LENGTH\n",
            "                        The maximum total sequence length for target text\n",
            "                        after tokenization. Sequences longer than this will be\n",
            "                        truncated, sequences shorter will be padded.\n",
            "  --val_max_target_length VAL_MAX_TARGET_LENGTH\n",
            "                        The maximum total sequence length for validation\n",
            "                        target text after tokenization. Sequences longer than\n",
            "                        this will be truncated, sequences shorter will be\n",
            "                        padded. This argument is also used to override the\n",
            "                        ``max_length`` param of ``model.generate``, which is\n",
            "                        used during ``evaluate`` and ``predict``.\n",
            "  --test_max_target_length TEST_MAX_TARGET_LENGTH\n",
            "                        The maximum total sequence length for test target text\n",
            "                        after tokenization. Sequences longer than this will be\n",
            "                        truncated, sequences shorter will be padded.\n",
            "  --n_train N_TRAIN     # training examples. -1 means use all.\n",
            "  --n_val N_VAL         # validation examples. -1 means use all.\n",
            "  --n_test N_TEST       # test examples. -1 means use all.\n",
            "  --src_lang SRC_LANG   Source language id for translation.\n",
            "  --tgt_lang TGT_LANG   Target language id for translation.\n",
            "  --eval_beams EVAL_BEAMS\n",
            "                        # num_beams to use for evaluation.\n",
            "  --no_ignore_pad_token_for_loss\n",
            "                        If only pad tokens should be ignored. This assumes\n",
            "                        that `config.pad_token_id` is defined.\n",
            "  --ignore_pad_token_for_loss [IGNORE_PAD_TOKEN_FOR_LOSS]\n",
            "                        If only pad tokens should be ignored. This assumes\n",
            "                        that `config.pad_token_id` is defined.\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        The output directory where the model predictions and\n",
            "                        checkpoints will be written.\n",
            "  --overwrite_output_dir [OVERWRITE_OUTPUT_DIR]\n",
            "                        Overwrite the content of the output directory.Use this\n",
            "                        to continue training if output_dir points to a\n",
            "                        checkpoint directory.\n",
            "  --do_train [DO_TRAIN]\n",
            "                        Whether to run training.\n",
            "  --do_eval [DO_EVAL]   Whether to run eval on the dev set.\n",
            "  --do_predict [DO_PREDICT]\n",
            "                        Whether to run predictions on the test set.\n",
            "  --evaluation_strategy {no,steps,epoch}\n",
            "                        The evaluation strategy to use.\n",
            "  --prediction_loss_only [PREDICTION_LOSS_ONLY]\n",
            "                        When performing evaluation and predictions, only\n",
            "                        returns the loss.\n",
            "  --per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE\n",
            "                        Batch size per GPU/TPU core/CPU for training.\n",
            "  --per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE\n",
            "                        Batch size per GPU/TPU core/CPU for evaluation.\n",
            "  --per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE\n",
            "                        Deprecated, the use of `--per_device_train_batch_size`\n",
            "                        is preferred. Batch size per GPU/TPU core/CPU for\n",
            "                        training.\n",
            "  --per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE\n",
            "                        Deprecated, the use of `--per_device_eval_batch_size`\n",
            "                        is preferred.Batch size per GPU/TPU core/CPU for\n",
            "                        evaluation.\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
            "                        Number of updates steps to accumulate before\n",
            "                        performing a backward/update pass.\n",
            "  --eval_accumulation_steps EVAL_ACCUMULATION_STEPS\n",
            "                        Number of predictions steps to accumulate before\n",
            "                        moving the tensors to the CPU.\n",
            "  --learning_rate LEARNING_RATE\n",
            "                        The initial learning rate for AdamW.\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "                        Weight decay for AdamW if we apply some.\n",
            "  --adam_beta1 ADAM_BETA1\n",
            "                        Beta1 for AdamW optimizer\n",
            "  --adam_beta2 ADAM_BETA2\n",
            "                        Beta2 for AdamW optimizer\n",
            "  --adam_epsilon ADAM_EPSILON\n",
            "                        Epsilon for AdamW optimizer.\n",
            "  --max_grad_norm MAX_GRAD_NORM\n",
            "                        Max gradient norm.\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS\n",
            "                        Total number of training epochs to perform.\n",
            "  --max_steps MAX_STEPS\n",
            "                        If > 0: set total number of training steps to perform.\n",
            "                        Override num_train_epochs.\n",
            "  --lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}\n",
            "                        The scheduler type to use.\n",
            "  --warmup_ratio WARMUP_RATIO\n",
            "                        Linear warmup over warmup_ratio fraction of total\n",
            "                        steps.\n",
            "  --warmup_steps WARMUP_STEPS\n",
            "                        Linear warmup over warmup_steps.\n",
            "  --logging_dir LOGGING_DIR\n",
            "                        Tensorboard log dir.\n",
            "  --logging_strategy {no,steps,epoch}\n",
            "                        The logging strategy to use.\n",
            "  --logging_first_step [LOGGING_FIRST_STEP]\n",
            "                        Log the first global_step\n",
            "  --logging_steps LOGGING_STEPS\n",
            "                        Log every X updates steps.\n",
            "  --save_strategy {no,steps,epoch}\n",
            "                        The checkpoint save strategy to use.\n",
            "  --save_steps SAVE_STEPS\n",
            "                        Save checkpoint every X updates steps.\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT\n",
            "                        Limit the total amount of checkpoints.Deletes the\n",
            "                        older checkpoints in the output_dir. Default is\n",
            "                        unlimited checkpoints\n",
            "  --no_cuda [NO_CUDA]   Do not use CUDA even when it is available\n",
            "  --seed SEED           Random seed that will be set at the beginning of\n",
            "                        training.\n",
            "  --fp16 [FP16]         Whether to use 16-bit (mixed) precision instead of\n",
            "                        32-bit\n",
            "  --fp16_opt_level FP16_OPT_LEVEL\n",
            "                        For fp16: Apex AMP optimization level selected in\n",
            "                        ['O0', 'O1', 'O2', and 'O3'].See details at\n",
            "                        https://nvidia.github.io/apex/amp.html\n",
            "  --fp16_backend {auto,amp,apex}\n",
            "                        The backend to be used for mixed precision.\n",
            "  --fp16_full_eval [FP16_FULL_EVAL]\n",
            "                        Whether to use full 16-bit precision evaluation\n",
            "                        instead of 32-bit\n",
            "  --local_rank LOCAL_RANK\n",
            "                        For distributed training: local_rank\n",
            "  --tpu_num_cores TPU_NUM_CORES\n",
            "                        TPU: Number of TPU cores (automatically passed by\n",
            "                        launcher script)\n",
            "  --tpu_metrics_debug [TPU_METRICS_DEBUG]\n",
            "                        Deprecated, the use of `--debug` is preferred. TPU:\n",
            "                        Whether to print debug metrics\n",
            "  --debug [DEBUG]       Whether to print debug metrics on TPU\n",
            "  --dataloader_drop_last [DATALOADER_DROP_LAST]\n",
            "                        Drop the last incomplete batch if it is not divisible\n",
            "                        by the batch size.\n",
            "  --eval_steps EVAL_STEPS\n",
            "                        Run an evaluation every X steps.\n",
            "  --dataloader_num_workers DATALOADER_NUM_WORKERS\n",
            "                        Number of subprocesses to use for data loading\n",
            "                        (PyTorch only). 0 means that the data will be loaded\n",
            "                        in the main process.\n",
            "  --past_index PAST_INDEX\n",
            "                        If >=0, uses the corresponding part of the output as\n",
            "                        the past state for next step.\n",
            "  --run_name RUN_NAME   An optional descriptor for the run. Notably used for\n",
            "                        wandb logging.\n",
            "  --disable_tqdm DISABLE_TQDM\n",
            "                        Whether or not to disable the tqdm progress bars.\n",
            "  --no_remove_unused_columns\n",
            "                        Remove columns not required by the model when using an\n",
            "                        nlp.Dataset.\n",
            "  --remove_unused_columns [REMOVE_UNUSED_COLUMNS]\n",
            "                        Remove columns not required by the model when using an\n",
            "                        nlp.Dataset.\n",
            "  --label_names LABEL_NAMES [LABEL_NAMES ...]\n",
            "                        The list of keys in your dictionary of inputs that\n",
            "                        correspond to the labels.\n",
            "  --load_best_model_at_end [LOAD_BEST_MODEL_AT_END]\n",
            "                        Whether or not to load the best model found during\n",
            "                        training at the end of training.\n",
            "  --metric_for_best_model METRIC_FOR_BEST_MODEL\n",
            "                        The metric to use to compare two different models.\n",
            "  --greater_is_better GREATER_IS_BETTER\n",
            "                        Whether the `metric_for_best_model` should be\n",
            "                        maximized or not.\n",
            "  --ignore_data_skip [IGNORE_DATA_SKIP]\n",
            "                        When resuming training, whether or not to skip the\n",
            "                        first epochs and batches to get to the same training\n",
            "                        data.\n",
            "  --sharded_ddp SHARDED_DDP\n",
            "                        Whether or not to use sharded DDP training (in\n",
            "                        distributed training only). The base option should be\n",
            "                        `simple`, `zero_dp_2` or `zero_dp_3` and you can add\n",
            "                        CPU-offload to `zero_dp_2` or `zero_dp_3` like this:\n",
            "                        zero_dp_2 offload` or `zero_dp_3 offload`. You can add\n",
            "                        auto-wrap to `zero_dp_2` or with the same syntax:\n",
            "                        zero_dp_2 auto_wrap` or `zero_dp_3 auto_wrap`.\n",
            "  --deepspeed DEEPSPEED\n",
            "                        Enable deepspeed and pass the path to deepspeed json\n",
            "                        config file (e.g. ds_config.json) or an already loaded\n",
            "                        json file as a dict\n",
            "  --label_smoothing_factor LABEL_SMOOTHING_FACTOR\n",
            "                        The label smoothing epsilon to apply (zero means no\n",
            "                        label smoothing).\n",
            "  --adafactor [ADAFACTOR]\n",
            "                        whether to use adafactor\n",
            "  --group_by_length [GROUP_BY_LENGTH]\n",
            "                        Whether or not to group samples of roughly the same\n",
            "                        length together when batching.\n",
            "  --report_to REPORT_TO [REPORT_TO ...]\n",
            "                        The list of integrations to report the results and\n",
            "                        logs to.\n",
            "  --ddp_find_unused_parameters DDP_FIND_UNUSED_PARAMETERS\n",
            "                        When using distributed training, the value of the flag\n",
            "                        `find_unused_parameters` passed to\n",
            "                        `DistributedDataParallel`.\n",
            "  --no_dataloader_pin_memory\n",
            "                        Whether or not to pin memory for DataLoader.\n",
            "  --dataloader_pin_memory [DATALOADER_PIN_MEMORY]\n",
            "                        Whether or not to pin memory for DataLoader.\n",
            "  --skip_memory_metrics [SKIP_MEMORY_METRICS]\n",
            "                        Whether or not to skip adding of memory profiler\n",
            "                        reports to metrics.\n",
            "  --label_smoothing LABEL_SMOOTHING\n",
            "                        The label smoothing epsilon to apply (if not zero).\n",
            "  --sortish_sampler [SORTISH_SAMPLER]\n",
            "                        Whether to SortishSamler or not.\n",
            "  --predict_with_generate [PREDICT_WITH_GENERATE]\n",
            "                        Whether to use generate to calculate generative\n",
            "                        metrics (ROUGE, BLEU).\n",
            "  --encoder_layerdrop ENCODER_LAYERDROP\n",
            "                        Encoder layer dropout probability. Goes into\n",
            "                        model.config.\n",
            "  --decoder_layerdrop DECODER_LAYERDROP\n",
            "                        Decoder layer dropout probability. Goes into\n",
            "                        model.config.\n",
            "  --dropout DROPOUT     Dropout probability. Goes into model.config.\n",
            "  --attention_dropout ATTENTION_DROPOUT\n",
            "                        Attention dropout probability. Goes into model.config.\n",
            "  --lr_scheduler LR_SCHEDULER\n",
            "                        Which lr scheduler to use. Selected in ['constant',\n",
            "                        'constant_w_warmup', 'cosine', 'cosine_w_restarts',\n",
            "                        'linear', 'polynomial']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0HQX4_IdtEm"
      },
      "source": [
        "# !export XSUM_DIR=/content/drive/inter_iit/data/import os\n",
        "import os\n",
        "os.environ['DRIVE_PATH'] = '/content/drive/MyDrive/inter_iit'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q50-pbL6ef3G",
        "outputId": "99cc7080-3b75-410d-93ee-24d2528face3"
      },
      "source": [
        "!python finetune_trainer.py \\\n",
        "    --model_name_or_path  $DRIVE_PATH/summ_outs/distilbart-12-6-e13 \\\n",
        "    --data_dir $DRIVE_PATH/article_english/mobile_only/ \\\n",
        "    --output_dir $DRIVE_PATH/summ_outs/distilbart-12-6-e13-e10-mobile_only/ \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --do_train --do_eval \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --predict_with_generate \\\n",
        "    --n_val 100 \\\n",
        "    --max_target_length=60 --val_max_target_length=60 --test_max_target_length=100 \\\n",
        "    --freeze_embeds \\\n",
        "    --num_train_epochs 200 \\\n",
        "    --per_device_train_batch_size 2 \\\n",
        "    --per_device_eval_batch_size 2 \\\n",
        "# --do_eval --do_predict \\\n",
        "# sshleifer/distilbart-xsum-12-6 \\\n",
        "# --freeze_encoder"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 14:30:16.449132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "03/22/2021 14:30:18 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/22/2021 14:30:18 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=200.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Mar22_14-30-18_9b5cd629bdfe', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, label_smoothing=0.0, sortish_sampler=False, predict_with_generate=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
            "[INFO|configuration_utils.py:466] 2021-03-22 14:30:18,739 >> loading configuration file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/config.json\n",
            "[INFO|configuration_utils.py:504] 2021-03-22 14:30:18,740 >> Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e3/\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": [\n",
            "    2\n",
            "  ],\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.5,\n",
            "  \"max_length\": 62,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 11,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"save_step\": 58,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {},\n",
            "  \"transformers_version\": \"4.5.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:466] 2021-03-22 14:30:18,741 >> loading configuration file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/config.json\n",
            "[INFO|configuration_utils.py:504] 2021-03-22 14:30:18,742 >> Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e3/\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": [\n",
            "    2\n",
            "  ],\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.5,\n",
            "  \"max_length\": 62,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 11,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"save_step\": 58,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {},\n",
            "  \"transformers_version\": \"4.5.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1637] 2021-03-22 14:30:18,743 >> Didn't find file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1637] 2021-03-22 14:30:18,744 >> Didn't find file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-22 14:30:18,745 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1049] 2021-03-22 14:30:18,879 >> loading weights file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1167] 2021-03-22 14:30:33,324 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:1176] 2021-03-22 14:30:33,324 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "03/22/2021 14:30:33 - INFO - utils -   setting model.config to task specific params for summarization:\n",
            " {}\n",
            "03/22/2021 14:30:33 - INFO - utils -   note: command line args may override some of these\n",
            "03/22/2021 14:30:36 - INFO - __main__ -   *** Train ***\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:856: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:883] 2021-03-22 14:30:36,586 >> Loading model from /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13).\n",
            "[INFO|configuration_utils.py:466] 2021-03-22 14:30:36,587 >> loading configuration file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/config.json\n",
            "[INFO|configuration_utils.py:504] 2021-03-22 14:30:36,588 >> Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e3/\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": [\n",
            "    2\n",
            "  ],\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.5,\n",
            "  \"max_length\": 62,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 11,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"save_step\": 58,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {},\n",
            "  \"transformers_version\": \"4.5.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1049] 2021-03-22 14:30:36,589 >> loading weights file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1167] 2021-03-22 14:30:50,756 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:1176] 2021-03-22 14:30:50,756 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "[INFO|trainer.py:975] 2021-03-22 14:30:51,417 >> ***** Running training *****\n",
            "[INFO|trainer.py:976] 2021-03-22 14:30:51,417 >>   Num examples = 899\n",
            "[INFO|trainer.py:977] 2021-03-22 14:30:51,417 >>   Num Epochs = 200\n",
            "[INFO|trainer.py:978] 2021-03-22 14:30:51,417 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:979] 2021-03-22 14:30:51,417 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "[INFO|trainer.py:980] 2021-03-22 14:30:51,417 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:981] 2021-03-22 14:30:51,417 >>   Total optimization steps = 90000\n",
            "[INFO|trainer.py:1000] 2021-03-22 14:30:51,419 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:1001] 2021-03-22 14:30:51,419 >>   Continuing training from epoch 40\n",
            "[INFO|trainer.py:1002] 2021-03-22 14:30:51,419 >>   Continuing training from global step 18000\n",
            "[INFO|trainer.py:1005] 2021-03-22 14:30:51,419 >>   Will skip the first 40 epochs then the first 0 batches in the first epoch.\n",
            "  0% 0/90000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.3192, 'learning_rate': 2.9833333333333335e-05, 'epoch': 41.11}\n",
            " 21% 18500/90000 [03:10<4:36:06,  4.32it/s][INFO|trainer.py:1804] 2021-03-22 14:34:02,315 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:34:02,315 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:34:02,315 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:12,  3.71it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:13,  3.44it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:18,  2.53it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:17,  2.60it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:19,  2.31it/s]\u001b[A\n",
            " 14% 7/50 [00:03<00:21,  2.04it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:18,  2.30it/s]\u001b[A\n",
            " 18% 9/50 [00:03<00:19,  2.14it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:18,  2.14it/s]\u001b[A\n",
            " 22% 11/50 [00:04<00:17,  2.17it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:16,  2.24it/s]\u001b[A\n",
            " 26% 13/50 [00:05<00:17,  2.18it/s]\u001b[A\n",
            " 28% 14/50 [00:06<00:16,  2.21it/s]\u001b[A\n",
            " 30% 15/50 [00:06<00:16,  2.07it/s]\u001b[A\n",
            " 32% 16/50 [00:07<00:17,  1.95it/s]\u001b[A\n",
            " 34% 17/50 [00:07<00:15,  2.10it/s]\u001b[A\n",
            " 36% 18/50 [00:08<00:16,  1.92it/s]\u001b[A\n",
            " 38% 19/50 [00:08<00:15,  2.04it/s]\u001b[A\n",
            " 40% 20/50 [00:09<00:16,  1.86it/s]\u001b[A\n",
            " 42% 21/50 [00:09<00:15,  1.88it/s]\u001b[A\n",
            " 44% 22/50 [00:10<00:14,  1.92it/s]\u001b[A\n",
            " 46% 23/50 [00:10<00:14,  1.92it/s]\u001b[A\n",
            " 48% 24/50 [00:11<00:12,  2.02it/s]\u001b[A\n",
            " 50% 25/50 [00:11<00:12,  1.93it/s]\u001b[A\n",
            " 52% 26/50 [00:12<00:11,  2.07it/s]\u001b[A\n",
            " 54% 27/50 [00:12<00:11,  2.08it/s]\u001b[A\n",
            " 56% 28/50 [00:13<00:08,  2.47it/s]\u001b[A\n",
            " 58% 29/50 [00:13<00:09,  2.30it/s]\u001b[A\n",
            " 60% 30/50 [00:14<00:09,  2.13it/s]\u001b[A\n",
            " 62% 31/50 [00:14<00:08,  2.28it/s]\u001b[A\n",
            " 64% 32/50 [00:15<00:08,  2.06it/s]\u001b[A\n",
            " 66% 33/50 [00:15<00:08,  1.96it/s]\u001b[A\n",
            " 68% 34/50 [00:16<00:07,  2.05it/s]\u001b[A\n",
            " 70% 35/50 [00:16<00:06,  2.29it/s]\u001b[A\n",
            " 72% 36/50 [00:16<00:05,  2.47it/s]\u001b[A\n",
            " 74% 37/50 [00:17<00:05,  2.53it/s]\u001b[A\n",
            " 76% 38/50 [00:17<00:04,  2.48it/s]\u001b[A\n",
            " 78% 39/50 [00:17<00:04,  2.65it/s]\u001b[A\n",
            " 80% 40/50 [00:18<00:04,  2.23it/s]\u001b[A\n",
            " 82% 41/50 [00:18<00:04,  2.19it/s]\u001b[A\n",
            " 84% 42/50 [00:19<00:03,  2.29it/s]\u001b[A\n",
            " 86% 43/50 [00:19<00:03,  2.06it/s]\u001b[A\n",
            " 88% 44/50 [00:20<00:03,  1.89it/s]\u001b[A\n",
            " 90% 45/50 [00:20<00:02,  2.19it/s]\u001b[A\n",
            " 92% 46/50 [00:21<00:01,  2.30it/s]\u001b[A\n",
            " 94% 47/50 [00:21<00:01,  2.30it/s]\u001b[A\n",
            " 96% 48/50 [00:22<00:00,  2.13it/s]\u001b[A\n",
            " 98% 49/50 [00:22<00:00,  1.83it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.0614864826202393, 'eval_rouge1': 44.2435, 'eval_rouge2': 28.3927, 'eval_rougeL': 41.0879, 'eval_rougeLsum': 41.2117, 'eval_gen_len': 19.5, 'eval_runtime': 24.3095, 'eval_samples_per_second': 4.114, 'epoch': 41.11}\n",
            " 21% 18500/90000 [03:35<4:36:06,  4.32it/s]\n",
            "100% 50/50 [00:23<00:00,  1.80it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:1587] 2021-03-22 14:34:26,629 >> Saving model checkpoint to /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-18500\n",
            "[INFO|configuration_utils.py:314] 2021-03-22 14:34:26,634 >> Configuration saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-18500/config.json\n",
            "[INFO|modeling_utils.py:837] 2021-03-22 14:34:30,831 >> Model weights saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-18500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-03-22 14:34:30,837 >> tokenizer config file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-18500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-03-22 14:34:30,840 >> Special tokens file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-18500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.3325, 'learning_rate': 2.966666666666667e-05, 'epoch': 42.22}\n",
            " 21% 19000/90000 [07:23<7:21:17,  2.68it/s][INFO|trainer.py:1804] 2021-03-22 14:38:15,233 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:38:15,233 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:38:15,234 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:15,  3.02it/s]\u001b[A\n",
            "  6% 3/50 [00:01<00:16,  2.90it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:20,  2.30it/s]\u001b[A\n",
            " 10% 5/50 [00:02<00:18,  2.42it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:19,  2.23it/s]\u001b[A\n",
            " 14% 7/50 [00:03<00:20,  2.06it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:18,  2.33it/s]\u001b[A\n",
            " 18% 9/50 [00:04<00:20,  2.01it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:19,  2.06it/s]\u001b[A\n",
            " 22% 11/50 [00:05<00:18,  2.10it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:17,  2.21it/s]\u001b[A\n",
            " 26% 13/50 [00:05<00:16,  2.18it/s]\u001b[A\n",
            " 28% 14/50 [00:06<00:16,  2.20it/s]\u001b[A\n",
            " 30% 15/50 [00:06<00:17,  1.99it/s]\u001b[A\n",
            " 32% 16/50 [00:07<00:17,  1.90it/s]\u001b[A\n",
            " 34% 17/50 [00:07<00:16,  2.01it/s]\u001b[A\n",
            " 36% 18/50 [00:08<00:19,  1.65it/s]\u001b[A\n",
            " 38% 19/50 [00:09<00:18,  1.72it/s]\u001b[A\n",
            " 40% 20/50 [00:10<00:18,  1.60it/s]\u001b[A\n",
            " 42% 21/50 [00:10<00:17,  1.70it/s]\u001b[A\n",
            " 44% 22/50 [00:11<00:15,  1.77it/s]\u001b[A\n",
            " 46% 23/50 [00:11<00:14,  1.85it/s]\u001b[A\n",
            " 48% 24/50 [00:11<00:12,  2.02it/s]\u001b[A\n",
            " 50% 25/50 [00:12<00:12,  1.93it/s]\u001b[A\n",
            " 52% 26/50 [00:12<00:11,  2.11it/s]\u001b[A\n",
            " 54% 27/50 [00:13<00:11,  2.06it/s]\u001b[A\n",
            " 56% 28/50 [00:13<00:09,  2.43it/s]\u001b[A\n",
            " 58% 29/50 [00:14<00:08,  2.40it/s]\u001b[A\n",
            " 60% 30/50 [00:14<00:09,  2.11it/s]\u001b[A\n",
            " 62% 31/50 [00:15<00:08,  2.24it/s]\u001b[A\n",
            " 64% 32/50 [00:15<00:08,  2.01it/s]\u001b[A\n",
            " 66% 33/50 [00:16<00:08,  1.93it/s]\u001b[A\n",
            " 68% 34/50 [00:16<00:07,  2.11it/s]\u001b[A\n",
            " 70% 35/50 [00:16<00:06,  2.44it/s]\u001b[A\n",
            " 72% 36/50 [00:17<00:05,  2.57it/s]\u001b[A\n",
            " 74% 37/50 [00:17<00:04,  2.76it/s]\u001b[A\n",
            " 76% 38/50 [00:17<00:04,  2.73it/s]\u001b[A\n",
            " 78% 39/50 [00:18<00:03,  2.83it/s]\u001b[A\n",
            " 80% 40/50 [00:18<00:04,  2.33it/s]\u001b[A\n",
            " 82% 41/50 [00:19<00:03,  2.39it/s]\u001b[A\n",
            " 84% 42/50 [00:19<00:03,  2.50it/s]\u001b[A\n",
            " 86% 43/50 [00:20<00:03,  2.23it/s]\u001b[A\n",
            " 88% 44/50 [00:20<00:03,  1.99it/s]\u001b[A\n",
            " 90% 45/50 [00:21<00:02,  2.22it/s]\u001b[A\n",
            " 92% 46/50 [00:21<00:01,  2.38it/s]\u001b[A\n",
            " 94% 47/50 [00:21<00:01,  2.58it/s]\u001b[A\n",
            " 96% 48/50 [00:22<00:00,  2.40it/s]\u001b[A\n",
            " 98% 49/50 [00:22<00:00,  2.21it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.040318012237549, 'eval_rouge1': 47.0025, 'eval_rouge2': 30.5331, 'eval_rougeL': 43.2113, 'eval_rougeLsum': 43.5332, 'eval_gen_len': 19.2, 'eval_runtime': 24.1177, 'eval_samples_per_second': 4.146, 'epoch': 42.22}\n",
            " 21% 19000/90000 [07:47<7:21:17,  2.68it/s]\n",
            "100% 50/50 [00:23<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:1587] 2021-03-22 14:38:39,355 >> Saving model checkpoint to /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19000\n",
            "[INFO|configuration_utils.py:314] 2021-03-22 14:38:39,360 >> Configuration saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19000/config.json\n",
            "[INFO|modeling_utils.py:837] 2021-03-22 14:38:44,896 >> Model weights saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-03-22 14:38:44,902 >> tokenizer config file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-03-22 14:38:44,906 >> Special tokens file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.283, 'learning_rate': 2.95e-05, 'epoch': 43.33}\n",
            " 22% 19500/90000 [11:30<9:26:32,  2.07it/s][INFO|trainer.py:1804] 2021-03-22 14:42:22,207 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:42:22,207 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:42:22,207 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:12,  3.86it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:12,  3.70it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:17,  2.60it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:16,  2.71it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:17,  2.46it/s]\u001b[A\n",
            " 14% 7/50 [00:02<00:19,  2.17it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:17,  2.41it/s]\u001b[A\n",
            " 18% 9/50 [00:03<00:19,  2.11it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:18,  2.12it/s]\u001b[A\n",
            " 22% 11/50 [00:04<00:18,  2.16it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:16,  2.27it/s]\u001b[A\n",
            " 26% 13/50 [00:05<00:16,  2.26it/s]\u001b[A\n",
            " 28% 14/50 [00:05<00:15,  2.39it/s]\u001b[A\n",
            " 30% 15/50 [00:06<00:15,  2.21it/s]\u001b[A\n",
            " 32% 16/50 [00:06<00:15,  2.21it/s]\u001b[A\n",
            " 34% 17/50 [00:07<00:14,  2.35it/s]\u001b[A\n",
            " 36% 18/50 [00:07<00:15,  2.03it/s]\u001b[A\n",
            " 38% 19/50 [00:08<00:14,  2.09it/s]\u001b[A\n",
            " 40% 20/50 [00:08<00:15,  1.91it/s]\u001b[A\n",
            " 42% 21/50 [00:09<00:14,  1.96it/s]\u001b[A\n",
            " 44% 22/50 [00:09<00:13,  2.10it/s]\u001b[A\n",
            " 46% 23/50 [00:10<00:11,  2.30it/s]\u001b[A\n",
            " 48% 24/50 [00:10<00:10,  2.39it/s]\u001b[A\n",
            " 50% 25/50 [00:11<00:11,  2.25it/s]\u001b[A\n",
            " 52% 26/50 [00:11<00:10,  2.37it/s]\u001b[A\n",
            " 54% 27/50 [00:12<00:10,  2.15it/s]\u001b[A\n",
            " 56% 28/50 [00:12<00:08,  2.46it/s]\u001b[A\n",
            " 58% 29/50 [00:12<00:08,  2.42it/s]\u001b[A\n",
            " 60% 30/50 [00:13<00:09,  2.21it/s]\u001b[A\n",
            " 62% 31/50 [00:13<00:08,  2.34it/s]\u001b[A\n",
            " 64% 32/50 [00:14<00:08,  2.09it/s]\u001b[A\n",
            " 66% 33/50 [00:14<00:08,  1.94it/s]\u001b[A\n",
            " 68% 34/50 [00:15<00:07,  2.08it/s]\u001b[A\n",
            " 70% 35/50 [00:15<00:06,  2.31it/s]\u001b[A\n",
            " 72% 36/50 [00:15<00:05,  2.54it/s]\u001b[A\n",
            " 74% 37/50 [00:16<00:04,  2.70it/s]\u001b[A\n",
            " 76% 38/50 [00:16<00:04,  2.45it/s]\u001b[A\n",
            " 78% 39/50 [00:16<00:04,  2.61it/s]\u001b[A\n",
            " 80% 40/50 [00:17<00:04,  2.25it/s]\u001b[A\n",
            " 82% 41/50 [00:17<00:03,  2.33it/s]\u001b[A\n",
            " 84% 42/50 [00:18<00:03,  2.53it/s]\u001b[A\n",
            " 86% 43/50 [00:18<00:03,  2.16it/s]\u001b[A\n",
            " 88% 44/50 [00:19<00:03,  1.99it/s]\u001b[A\n",
            " 90% 45/50 [00:19<00:02,  2.30it/s]\u001b[A\n",
            " 92% 46/50 [00:20<00:01,  2.55it/s]\u001b[A\n",
            " 94% 47/50 [00:20<00:01,  2.69it/s]\u001b[A\n",
            " 96% 48/50 [00:20<00:00,  2.43it/s]\u001b[A\n",
            " 98% 49/50 [00:21<00:00,  2.19it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.098881483078003, 'eval_rouge1': 45.4491, 'eval_rouge2': 30.9083, 'eval_rougeL': 42.315, 'eval_rougeLsum': 42.1919, 'eval_gen_len': 17.8, 'eval_runtime': 22.821, 'eval_samples_per_second': 4.382, 'epoch': 43.33}\n",
            " 22% 19500/90000 [11:53<9:26:32,  2.07it/s]\n",
            "100% 50/50 [00:22<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:1587] 2021-03-22 14:42:45,045 >> Saving model checkpoint to /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19500\n",
            "[INFO|configuration_utils.py:314] 2021-03-22 14:42:45,051 >> Configuration saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19500/config.json\n",
            "[INFO|modeling_utils.py:837] 2021-03-22 14:42:49,654 >> Model weights saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-03-22 14:42:49,660 >> tokenizer config file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-03-22 14:42:49,664 >> Special tokens file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-19500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.2645, 'learning_rate': 2.9333333333333333e-05, 'epoch': 44.44}\n",
            " 22% 20000/90000 [15:35<8:18:57,  2.34it/s][INFO|trainer.py:1804] 2021-03-22 14:46:27,388 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:46:27,388 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:46:27,388 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:12,  3.99it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:13,  3.52it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:18,  2.53it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:16,  2.76it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:17,  2.48it/s]\u001b[A\n",
            " 14% 7/50 [00:02<00:19,  2.19it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:17,  2.45it/s]\u001b[A\n",
            " 18% 9/50 [00:03<00:19,  2.16it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:18,  2.12it/s]\u001b[A\n",
            " 22% 11/50 [00:04<00:17,  2.19it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:16,  2.29it/s]\u001b[A\n",
            " 26% 13/50 [00:05<00:16,  2.23it/s]\u001b[A\n",
            " 28% 14/50 [00:05<00:14,  2.43it/s]\u001b[A\n",
            " 30% 15/50 [00:06<00:14,  2.40it/s]\u001b[A\n",
            " 32% 16/50 [00:06<00:15,  2.13it/s]\u001b[A\n",
            " 34% 17/50 [00:07<00:14,  2.22it/s]\u001b[A\n",
            " 36% 18/50 [00:07<00:16,  1.99it/s]\u001b[A\n",
            " 38% 19/50 [00:08<00:16,  1.94it/s]\u001b[A\n",
            " 40% 20/50 [00:09<00:17,  1.76it/s]\u001b[A\n",
            " 42% 21/50 [00:09<00:15,  1.82it/s]\u001b[A\n",
            " 44% 22/50 [00:10<00:14,  1.87it/s]\u001b[A\n",
            " 46% 23/50 [00:10<00:13,  1.95it/s]\u001b[A\n",
            " 48% 24/50 [00:11<00:12,  2.03it/s]\u001b[A\n",
            " 50% 25/50 [00:11<00:13,  1.84it/s]\u001b[A\n",
            " 52% 26/50 [00:12<00:11,  2.00it/s]\u001b[A\n",
            " 54% 27/50 [00:12<00:11,  2.05it/s]\u001b[A\n",
            " 56% 28/50 [00:12<00:08,  2.47it/s]\u001b[A\n",
            " 58% 29/50 [00:13<00:08,  2.43it/s]\u001b[A\n",
            " 60% 30/50 [00:13<00:08,  2.26it/s]\u001b[A\n",
            " 62% 31/50 [00:14<00:08,  2.30it/s]\u001b[A\n",
            " 64% 32/50 [00:14<00:08,  2.04it/s]\u001b[A\n",
            " 66% 33/50 [00:15<00:08,  1.95it/s]\u001b[A\n",
            " 68% 34/50 [00:15<00:07,  2.09it/s]\u001b[A\n",
            " 70% 35/50 [00:16<00:06,  2.43it/s]\u001b[A\n",
            " 72% 36/50 [00:16<00:05,  2.52it/s]\u001b[A\n",
            " 74% 37/50 [00:16<00:04,  2.64it/s]\u001b[A\n",
            " 76% 38/50 [00:17<00:04,  2.70it/s]\u001b[A\n",
            " 78% 39/50 [00:17<00:03,  2.77it/s]\u001b[A\n",
            " 80% 40/50 [00:18<00:04,  2.27it/s]\u001b[A\n",
            " 82% 41/50 [00:18<00:03,  2.34it/s]\u001b[A\n",
            " 84% 42/50 [00:18<00:03,  2.55it/s]\u001b[A\n",
            " 86% 43/50 [00:19<00:03,  2.24it/s]\u001b[A\n",
            " 88% 44/50 [00:19<00:02,  2.04it/s]\u001b[A\n",
            " 90% 45/50 [00:20<00:02,  2.26it/s]\u001b[A\n",
            " 92% 46/50 [00:20<00:01,  2.45it/s]\u001b[A\n",
            " 94% 47/50 [00:20<00:01,  2.57it/s]\u001b[A\n",
            " 96% 48/50 [00:21<00:00,  2.36it/s]\u001b[A\n",
            " 98% 49/50 [00:21<00:00,  2.15it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.113783836364746, 'eval_rouge1': 46.5874, 'eval_rouge2': 31.6952, 'eval_rougeL': 43.7079, 'eval_rougeLsum': 43.9399, 'eval_gen_len': 18.8, 'eval_runtime': 23.3291, 'eval_samples_per_second': 4.286, 'epoch': 44.44}\n",
            " 22% 20000/90000 [15:59<8:18:57,  2.34it/s]\n",
            "100% 50/50 [00:22<00:00,  2.00it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:1587] 2021-03-22 14:46:50,721 >> Saving model checkpoint to /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20000\n",
            "[INFO|configuration_utils.py:314] 2021-03-22 14:46:50,726 >> Configuration saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20000/config.json\n",
            "[INFO|modeling_utils.py:837] 2021-03-22 14:46:55,384 >> Model weights saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-03-22 14:46:55,393 >> tokenizer config file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-03-22 14:46:55,396 >> Special tokens file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20000/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.2518, 'learning_rate': 2.9166666666666666e-05, 'epoch': 45.56}\n",
            " 23% 20500/90000 [19:40<7:33:30,  2.55it/s][INFO|trainer.py:1804] 2021-03-22 14:50:31,648 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:50:31,649 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:50:31,649 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:12,  3.70it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:13,  3.45it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:18,  2.49it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:16,  2.69it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:18,  2.40it/s]\u001b[A\n",
            " 14% 7/50 [00:02<00:19,  2.16it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:17,  2.46it/s]\u001b[A\n",
            " 18% 9/50 [00:03<00:18,  2.17it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:18,  2.13it/s]\u001b[A\n",
            " 22% 11/50 [00:04<00:17,  2.18it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:16,  2.24it/s]\u001b[A\n",
            " 26% 13/50 [00:05<00:17,  2.16it/s]\u001b[A\n",
            " 28% 14/50 [00:06<00:16,  2.22it/s]\u001b[A\n",
            " 30% 15/50 [00:06<00:16,  2.14it/s]\u001b[A\n",
            " 32% 16/50 [00:07<00:17,  1.95it/s]\u001b[A\n",
            " 34% 17/50 [00:07<00:15,  2.08it/s]\u001b[A\n",
            " 36% 18/50 [00:08<00:16,  1.90it/s]\u001b[A\n",
            " 38% 19/50 [00:08<00:15,  1.99it/s]\u001b[A\n",
            " 40% 20/50 [00:09<00:16,  1.81it/s]\u001b[A\n",
            " 42% 21/50 [00:09<00:15,  1.86it/s]\u001b[A\n",
            " 44% 22/50 [00:10<00:13,  2.04it/s]\u001b[A\n",
            " 46% 23/50 [00:10<00:11,  2.25it/s]\u001b[A\n",
            " 48% 24/50 [00:10<00:10,  2.40it/s]\u001b[A\n",
            " 50% 25/50 [00:11<00:12,  2.06it/s]\u001b[A\n",
            " 52% 26/50 [00:11<00:10,  2.27it/s]\u001b[A\n",
            " 54% 27/50 [00:12<00:10,  2.24it/s]\u001b[A\n",
            " 56% 28/50 [00:12<00:08,  2.59it/s]\u001b[A\n",
            " 58% 29/50 [00:13<00:08,  2.52it/s]\u001b[A\n",
            " 60% 30/50 [00:13<00:08,  2.32it/s]\u001b[A\n",
            " 62% 31/50 [00:13<00:07,  2.43it/s]\u001b[A\n",
            " 64% 32/50 [00:14<00:08,  2.09it/s]\u001b[A\n",
            " 66% 33/50 [00:15<00:08,  1.95it/s]\u001b[A\n",
            " 68% 34/50 [00:15<00:07,  2.11it/s]\u001b[A\n",
            " 70% 35/50 [00:15<00:06,  2.40it/s]\u001b[A\n",
            " 72% 36/50 [00:16<00:05,  2.57it/s]\u001b[A\n",
            " 74% 37/50 [00:16<00:04,  2.68it/s]\u001b[A\n",
            " 76% 38/50 [00:16<00:04,  2.59it/s]\u001b[A\n",
            " 78% 39/50 [00:17<00:04,  2.71it/s]\u001b[A\n",
            " 80% 40/50 [00:17<00:04,  2.37it/s]\u001b[A\n",
            " 82% 41/50 [00:18<00:03,  2.37it/s]\u001b[A\n",
            " 84% 42/50 [00:18<00:03,  2.53it/s]\u001b[A\n",
            " 86% 43/50 [00:19<00:03,  2.09it/s]\u001b[A\n",
            " 88% 44/50 [00:19<00:03,  1.91it/s]\u001b[A\n",
            " 90% 45/50 [00:20<00:02,  2.20it/s]\u001b[A\n",
            " 92% 46/50 [00:20<00:01,  2.46it/s]\u001b[A\n",
            " 94% 47/50 [00:20<00:01,  2.50it/s]\u001b[A\n",
            " 96% 48/50 [00:21<00:00,  2.35it/s]\u001b[A\n",
            " 98% 49/50 [00:21<00:00,  2.17it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.14778995513916, 'eval_rouge1': 42.3616, 'eval_rouge2': 27.8678, 'eval_rougeL': 39.9406, 'eval_rougeLsum': 39.9196, 'eval_gen_len': 18.3, 'eval_runtime': 23.1336, 'eval_samples_per_second': 4.323, 'epoch': 45.56}\n",
            " 23% 20500/90000 [20:03<7:33:30,  2.55it/s]\n",
            "100% 50/50 [00:22<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:1587] 2021-03-22 14:50:54,786 >> Saving model checkpoint to /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20500\n",
            "[INFO|configuration_utils.py:314] 2021-03-22 14:50:54,792 >> Configuration saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20500/config.json\n",
            "[INFO|modeling_utils.py:837] 2021-03-22 14:51:00,355 >> Model weights saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-03-22 14:51:00,371 >> tokenizer config file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-03-22 14:51:00,423 >> Special tokens file saved in /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-e10-mobile_only/checkpoint-20500/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3221: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
            "  FutureWarning,\n",
            "{'loss': 0.2066, 'learning_rate': 2.9e-05, 'epoch': 46.67}\n",
            " 23% 21000/90000 [23:48<7:08:38,  2.68it/s][INFO|trainer.py:1804] 2021-03-22 14:54:40,310 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:1805] 2021-03-22 14:54:40,310 >>   Num examples = 100\n",
            "[INFO|trainer.py:1806] 2021-03-22 14:54:40,310 >>   Batch size = 2\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:14,  3.34it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:14,  3.24it/s]\u001b[A\n",
            "  8% 4/50 [00:01<00:19,  2.40it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:17,  2.60it/s]\u001b[A\n",
            " 12% 6/50 [00:02<00:17,  2.45it/s]\u001b[A\n",
            " 14% 7/50 [00:02<00:19,  2.18it/s]\u001b[A\n",
            " 16% 8/50 [00:03<00:18,  2.30it/s]\u001b[A\n",
            " 18% 9/50 [00:03<00:19,  2.07it/s]\u001b[A\n",
            " 20% 10/50 [00:04<00:19,  2.04it/s]\u001b[A\n",
            " 22% 11/50 [00:04<00:18,  2.12it/s]\u001b[A\n",
            " 24% 12/50 [00:05<00:17,  2.12it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"finetune_trainer.py\", line 367, in <module>\n",
            "    main()\n",
            "  File \"finetune_trainer.py\", line 305, in main\n",
            "    model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1134, in train\n",
            "    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1227, in _maybe_log_save_evaluate\n",
            "    metrics = self.evaluate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1703, in evaluate\n",
            "    metric_key_prefix=metric_key_prefix,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1834, in prediction_loop\n",
            "    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
            "  File \"/content/transformers/examples/legacy/seq2seq/seq2seq_trainer.py\", line 223, in prediction_step\n",
            "    **gen_kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\", line 1054, in generate\n",
            "    **model_kwargs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\", line 1774, in beam_search\n",
            "    eos_token_id=eos_token_id,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/generation_beam_search.py\", line 218, in process\n",
            "    if self._done[batch_idx]:\n",
            "KeyboardInterrupt\n",
            "\n",
            " 23% 21000/90000 [23:54<1:18:34, 14.63it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRXMEtBErzOX",
        "outputId": "35a05e2c-f873-46b3-8050-1867e0167912"
      },
      "source": [
        "!./run_eval.py $DRIVE_PATH/summ_outs/distilbart-12-6-e13/checkpoint-5000/ $DRIVE_PATH/article_english/test.source $DRIVE_PATH/summ_outs/distilbart-12-6-e13/dbart_test_generations_3000.txt \\\n",
        "    --task summarization \\\n",
        "    # --reference_path $DRIVE_PATH/article_english/val.target \\\n",
        "    # --score_path $DRIVE_PATH/summ_outs/distilbart-12-6-e13/iiit_rouge_val.json \\\n",
        "    #--n_obs 222 \\"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 15:58:01.118879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "100% 28/28 [00:34<00:00,  1.22s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94y_J01oKojf",
        "outputId": "9ebf8fb0-4e72-4069-a3c4-2c206b0dd5cc"
      },
      "source": [
        "!python finetune_trainer.py \\\n",
        "    --model_name_or_path  $DRIVE_PATH/summ_outs/distilbart-12-6-e13/checkpoint-17000/ \\\n",
        "    --data_dir $DRIVE_PATH/article_english/ \\\n",
        "    --output_dir $DRIVE_PATH/summ_outs/distilbart-12-6-e13-test/ \\\n",
        "    --learning_rate=3e-5 \\\n",
        "    --do_predict \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --predict_with_generate \\\n",
        "     --test_max_target_length=60 \\\n",
        "    # --freeze_embeds \\\n",
        "    # --num_train_epochs 200 \\\n",
        "    # --per_device_train_batch_size 2 \\\n",
        "    # --per_device_eval_batch_size 2 \\"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 13:55:28.760714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "03/23/2021 13:55:32 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/23/2021 13:55:32 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-test/', overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=True, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Mar23_13-55-31_5dd253f4bc9b', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13-test/', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, label_smoothing=0.0, sortish_sampler=False, predict_with_generate=True, encoder_layerdrop=None, decoder_layerdrop=None, dropout=None, attention_dropout=None, lr_scheduler='linear')\n",
            "[INFO|configuration_utils.py:470] 2021-03-23 13:55:33,026 >> loading configuration file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/config.json\n",
            "[INFO|configuration_utils.py:508] 2021-03-23 13:55:33,027 >> Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e3/\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": [\n",
            "    2\n",
            "  ],\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.5,\n",
            "  \"max_length\": 62,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 11,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"save_step\": 58,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {},\n",
            "  \"transformers_version\": \"4.5.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:470] 2021-03-23 13:55:33,029 >> loading configuration file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/config.json\n",
            "[INFO|configuration_utils.py:508] 2021-03-23 13:55:33,030 >> Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e3/\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"eos_token_ids\": [\n",
            "    2\n",
            "  ],\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.5,\n",
            "  \"max_length\": 62,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 11,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_beams\": 6,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"replacing_rate\": 0,\n",
            "  \"save_step\": 58,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"student_decoder_layers\": null,\n",
            "  \"student_encoder_layers\": null,\n",
            "  \"task_specific_params\": {},\n",
            "  \"transformers_version\": \"4.5.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1637] 2021-03-23 13:55:33,031 >> Didn't find file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1637] 2021-03-23 13:55:33,031 >> Didn't find file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1700] 2021-03-23 13:55:33,033 >> loading file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1049] 2021-03-23 13:55:34,801 >> loading weights file /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1167] 2021-03-23 13:56:00,123 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:1176] 2021-03-23 13:56:00,123 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/inter_iit/summ_outs/distilbart-12-6-e13/checkpoint-17000/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "03/23/2021 13:56:00 - INFO - utils -   setting model.config to task specific params for summarization:\n",
            " {}\n",
            "03/23/2021 13:56:00 - INFO - utils -   note: command line args may override some of these\n",
            "03/23/2021 13:56:09 - INFO - __main__ -   *** Predict ***\n",
            "[INFO|trainer.py:1808] 2021-03-23 13:56:09,206 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:1809] 2021-03-23 13:56:09,206 >>   Num examples = 225\n",
            "[INFO|trainer.py:1810] 2021-03-23 13:56:09,206 >>   Batch size = 8\n",
            "Traceback (most recent call last):\n",
            "  File \"finetune_trainer.py\", line 367, in <module>\n",
            "    main()\n",
            "  File \"finetune_trainer.py\", line 339, in main\n",
            "    test_output = trainer.predict(test_dataset=test_dataset, metric_key_prefix=\"test\")\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1767, in predict\n",
            "    test_dataloader, description=\"Prediction\", ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1837, in prediction_loop\n",
            "    for step, inputs in enumerate(dataloader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 557, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/transformers/examples/legacy/seq2seq/utils.py\", line 263, in __getitem__\n",
            "    assert tgt_line, f\"empty tgt line for index {index}\"\n",
            "AssertionError: empty tgt line for index 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDOYA-JcyKzh"
      },
      "source": [
        "# ! echo $DRIVE_PATH"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YyTk3DUygEm"
      },
      "source": [
        "#distilbart 17000 best chckpoint"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}